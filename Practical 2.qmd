---
title: "Practical 2"
---

## Question 1

```{r}
# Load necessary libraries
library(foreach)
library(doParallel)
library(knitr)

# Set up a parallel backend with one fewer than available cores
ncores <- parallel::detectCores() - 1
cl <- makeCluster(ncores)
registerDoParallel(cl)

# Number of simulations and sample size for each simulation
num_simulations <- 100
sample_size <- 100  # you can change this if needed

# Use a foreach loop to run the simulation 100 times
results <- foreach(i = 1:num_simulations, .combine = rbind) %dopar% {
  # Generate a random sample from an exponential distribution with mean = 1
  sample_data <- rexp(sample_size, rate = 1)
  
  # Calculate the mean and variance of the sample
  sample_mean <- mean(sample_data)
  sample_variance <- var(sample_data)
  
  # Return a vector with the mean and variance
  c(mean = sample_mean, variance = sample_variance)
}

# Stop the parallel cluster
stopCluster(cl)

# Display the first few rows of the results
cat("The results are :")
results
```

## Question 2

```{r}
# Load necessary libraries
library(MASS)         # For galaxies data
library(doParallel)   # For parallel backend
library(foreach)      # For the foreach loop

# Load the galaxies data
data(galaxies)

# Set the number of bootstrap samples
n_boot <- 10000

# Serial Bootstrapping
set.seed(123)
serial_time <- system.time({
  boot_medians_serial <- replicate(n_boot, {
    sample_data <- sample(galaxies, replace = TRUE)
    median(sample_data)
  })
})
cat("Serial processing time:\n")
print(serial_time)

# Parallel Bootstrapping: One Bootstrap per Iteration
# Set up parallel backend
ncores <- parallel::detectCores() - 1
cl <- makeCluster(ncores)
registerDoParallel(cl)

set.seed(123)
parallel_time <- system.time({
  boot_medians_parallel <- foreach(i = 1:n_boot, .packages = 'MASS') %dopar% {
    sample_data <- sample(galaxies, replace = TRUE)
    median(sample_data)
  }
})
cat("Parallel processing time (one bootstrap per iteration):\n")
print(parallel_time)

# Parallel Bootstrapping: 1000 Bootstraps per Iteration (Chunking)
# Determine number of chunks
chunk_size <- 1000
n_chunks <- n_boot / chunk_size  # here, 10 chunks if n_boot = 10000

set.seed(123)
chunk_parallel_time <- system.time({
  boot_medians_chunk <- foreach(i = 1:n_chunks, .packages = 'MASS', .combine = c) %dopar% {
    # For each chunk, perform 1000 bootstrap samples
    sapply(1:chunk_size, function(j) {
      sample_data <- sample(galaxies, replace = TRUE)
      median(sample_data)
    })
  }
})
cat("Parallel processing time (1000 bootstraps per iteration):\n")
print(chunk_parallel_time)

# Shut down the cluster
stopCluster(cl)
```

When each iteration is very quick (like a single bootstrap), parallel processing can add significant overhead and actually slow down the computation. However, when you increase the work per iteration (e.g., 1000 bootstraps per iteration), the computational load becomes large enough relative to the overhead that parallel processing offers a substantial speedup over serial processing.

## Question 3

```{r}
# Set simulation parameters
set.seed(123)        # For reproducibility
n <- 50              # Sample size
M <- 1000            # Number of simulation iterations
B <- 1000            # Number of bootstrap replicates per iteration

# Vector to record if the CI covers the true mean (1) for each simulation
coverage <- numeric(M)

for(i in 1:M) {
  # Draw a sample of size 50 from an exponential distribution (mean = 1)
  sample_data <- rexp(n, rate = 1)
  
  # Bootstrap: compute the mean for B bootstrap samples
  boot_means <- replicate(B, mean(sample(sample_data, size = n, replace = TRUE)))
  
  # Compute the 95% percentile bootstrap confidence interval
  ci <- quantile(boot_means, probs = c(0.025, 0.975))
  
  # Check if the true mean (1) falls within the CI
  coverage[i] <- as.numeric( (1 >= ci[1]) & (1 <= ci[2]) )
}

# Calculate the coverage probability
coverage_probability <- mean(coverage)
cat("Estimated coverage probability:", coverage_probability, "\n")


```

## Question 4

The code using irnorm wasn't working so I did it manually.

```{r}
library(iterators)
set.seed(1234)

# Create the iterator: 3 vectors each with 5 random normals
it <- irnorm(3, n = 5)

# Manually extract each element
vec1 <- nextElem(it)
vec2 <- nextElem(it)
vec3 <- nextElem(it)

# Print the vectors
print(list(vec1, vec2, vec3))
max <- c(max(vec1), max(vec2), max(vec3))
print(max)
# Load required libraries
#library(foreach)
#library(iterators)

# Set the seed for reproducibility
#set.seed(1234)

# Use foreach with irnorm to iterate over 3 vectors, each with 5 random normals
# Use .combine = c to collect the maximums into a vector
#largest_values <- foreach(vec = irnorm(3, n = 5), .combine = c) %do% {
#  max(vec)
#}

# Print the largest value from each vector
#print(largest_values)





```

##Question 5

```{r}
# Load necessary libraries
library(foreach)
library(iterators)
library(parallel)

# Set seed for reproducibility
set.seed(1234)

# This approach uses the 'foreach' and 'irnorm' iterator.
time_foreach <- system.time({
  result_foreach <- foreach(vec = irnorm(3, n = 5)) %do% {
    max(vec)
  }
})
cat("foreach result:\n")
print(result_foreach)
cat("foreach time:\n")
print(time_foreach)

# For parLapply, we first create a cluster.
ncores <- detectCores() - 1
cl <- makeCluster(ncores)
# Reset seed for reproducibility of the random vectors.
set.seed(1234)
# Generate the list of 3 vectors (each of length 5)
random_vectors <- replicate(3, rnorm(5), simplify = FALSE)
time_parLapply <- system.time({
  result_parLapply <- parLapply(cl, random_vectors, function(x) max(x))
}) 
# Stop the cluster when done.
stopCluster(cl)
cat("\nparLapply result:\n")
print(result_parLapply)
cat("parLapply time:\n")
print(time_parLapply)

# This sequential approach simply repeats the expression 3 times.
set.seed(1234)
time_replicate <- system.time({
  result_replicate <- replicate(3, max(rnorm(5)))
})
cat("\nreplicate result:\n")
print(result_replicate)
cat("replicate time:\n")
print(time_replicate)




# Load necessary libraries
library(foreach)
library(iterators)
library(parallel)

# Set seed for reproducibility
set.seed(1234)

### Method 1: Using foreach with a manually constructed iterator ###
# Instead of using irnorm (which may not terminate as expected),
# we pre-generate a list of 3 vectors, each with 5 random numbers.
random_vectors <- replicate(3, rnorm(5), simplify = FALSE)
# Create an iterator from the list
it <- iter(random_vectors)
result_foreach <- foreach(vec = it) %do% {
  max(vec)
}
cat("foreach result:\n")
print(result_foreach)

cat("foreach time:\n")
print(time_foreach)


### Method 2: Using parLapply ###
# Create a cluster. On macOS, PSOCK clusters are typical.
ncores <- detectCores() - 1
cl <- makeCluster(ncores)

time_parLapply <- system.time({
  # Wrap max in an anonymous function to ensure it is found on each worker.
  result_parLapply <- parLapply(cl, random_vectors, function(x) max(x))
})
cat("\nparLapply result:\n")
print(result_parLapply)
cat("parLapply time:\n")
print(time_parLapply)

# Stop the cluster
stopCluster(cl)

### Method 3: Using replicate ###
# Reset seed for fair comparison
set.seed(1234)
time_replicate <- system.time({
  result_replicate <- replicate(3, max(rnorm(5)))
})
cat("\nreplicate result:\n")
print(result_replicate)
cat("replicate time:\n")
print(time_replicate)


```
