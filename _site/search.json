[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home Page",
    "section": "",
    "text": "Welcome to My Practical Answers\nThank you for visiting! This site contains my solutions for Practical 2, covering key concepts and exercises.\nEach section includes detailed answers, explanations, and code implementations where necessary. Feel free to navigate through the different practicals using the menu above.\n\n\nThe link to Git :\n\n\nhttps://github.com/Tamika24/Practical-2"
  },
  {
    "objectID": "Practical2.html",
    "href": "Practical2.html",
    "title": "Practical 2",
    "section": "",
    "text": "# Load required packages\nlibrary(doParallel)\nlibrary(foreach)\n\nmv &lt;- function(i){\n  x &lt;- rexp(5, rate = 1)\n  c(mean = mean(x), variance = var(x))\n}\n# Create and register a parallel cluster\ncl &lt;- makeCluster(detectCores()-1)\nregisterDoParallel(cl)\n\n# Run the loop 100 times in parallel, row-binding the results\nresults &lt;- foreach(i = 1:100, .combine = rbind) %dopar% {\n mv(i)\n}\n\n# Stop the cluster\nstopCluster(cl)\n\n# Display the results\nprint(results)\n\n                mean   variance\nresult.1   1.1288992 0.73035518\nresult.2   0.7950107 0.21141747\nresult.3   0.3583200 0.06563397\nresult.4   0.8106077 0.78682642\nresult.5   1.5510018 3.64689240\nresult.6   1.4773638 1.56826896\nresult.7   0.4197574 0.13742353\nresult.8   1.1423358 2.53882291\nresult.9   0.4153431 0.01160518\nresult.10  0.2755864 0.11912366\nresult.11  1.2601540 1.07318467\nresult.12  1.7475335 2.92147586\nresult.13  1.3302222 3.87939260\nresult.14  0.6447782 0.34432987\nresult.15  1.0684831 1.32564220\nresult.16  1.7598558 0.93240282\nresult.17  0.9087562 1.09592852\nresult.18  1.5613996 2.26774037\nresult.19  0.7621280 0.35850302\nresult.20  0.7591938 0.85965785\nresult.21  1.5856916 0.51469177\nresult.22  1.0630074 2.07856419\nresult.23  1.2412400 1.18889830\nresult.24  0.6320390 0.20168502\nresult.25  0.4186786 0.04573243\nresult.26  1.2200079 1.55888103\nresult.27  0.8936621 0.63438404\nresult.28  0.7822015 0.66555297\nresult.29  0.4296315 0.09811357\nresult.30  1.5339749 2.93832528\nresult.31  1.3359452 0.77659875\nresult.32  1.2243813 0.25632603\nresult.33  1.3048900 1.84245975\nresult.34  0.8163190 0.16284323\nresult.35  1.4042810 0.50133200\nresult.36  0.7544900 0.67435215\nresult.37  0.9553073 0.22037393\nresult.38  0.9734162 0.34116689\nresult.39  1.0024035 1.30177623\nresult.40  1.1883327 1.76926033\nresult.41  0.3378147 0.19666427\nresult.42  1.1764654 3.37297975\nresult.43  1.1048075 0.94397295\nresult.44  1.3092370 0.59307765\nresult.45  1.0635728 0.96833769\nresult.46  1.8146406 1.00234279\nresult.47  1.3141530 0.72582506\nresult.48  2.0089726 5.40000362\nresult.49  0.9712787 1.06853051\nresult.50  2.0516110 2.42725116\nresult.51  1.1371917 0.87397629\nresult.52  0.3539980 0.15217264\nresult.53  2.1923255 3.28910959\nresult.54  1.1433682 0.61960775\nresult.55  0.6413180 0.23746845\nresult.56  0.9745443 0.31693026\nresult.57  1.2596828 0.46997846\nresult.58  0.6733489 0.17728644\nresult.59  0.6558711 0.11192639\nresult.60  0.2869652 0.05203253\nresult.61  0.7912332 0.88691298\nresult.62  1.0032570 0.85523386\nresult.63  0.9848363 0.94665859\nresult.64  0.4565007 0.13055929\nresult.65  0.8776881 1.03896356\nresult.66  0.8329913 2.14057435\nresult.67  1.7084647 2.30072970\nresult.68  1.7559917 1.49152952\nresult.69  0.9423884 1.16791953\nresult.70  1.0121772 1.47473197\nresult.71  0.7984874 0.23523992\nresult.72  1.0125662 1.48196792\nresult.73  0.6378034 0.20705218\nresult.74  0.8283713 1.01516138\nresult.75  0.3757705 0.07238936\nresult.76  1.2645921 1.99987744\nresult.77  0.7874910 0.23039238\nresult.78  0.3777147 0.11149824\nresult.79  1.1175695 1.61746429\nresult.80  1.7247620 2.84546887\nresult.81  1.0671121 1.02452935\nresult.82  1.7984154 2.21659650\nresult.83  0.6359398 0.17242037\nresult.84  0.9046533 0.42237020\nresult.85  1.4731696 2.83351935\nresult.86  1.2016286 2.43604612\nresult.87  0.4626624 0.08911491\nresult.88  1.0546414 1.48970702\nresult.89  0.5144586 0.14163034\nresult.90  1.8080100 6.41394861\nresult.91  1.8079900 0.56166578\nresult.92  1.2877671 0.61062531\nresult.93  0.9869252 2.10192679\nresult.94  1.3554280 0.59870810\nresult.95  1.7970576 2.45921712\nresult.96  1.4589206 0.50374303\nresult.97  0.5805582 0.21950760\nresult.98  0.7262184 0.51128350\nresult.99  1.3386200 4.30815936\nresult.100 0.8891374 0.67267828"
  },
  {
    "objectID": "Practical2.html#question-1",
    "href": "Practical2.html#question-1",
    "title": "Practical 2",
    "section": "",
    "text": "# Load required packages\nlibrary(doParallel)\nlibrary(foreach)\n\nmv &lt;- function(i){\n  x &lt;- rexp(5, rate = 1)\n  c(mean = mean(x), variance = var(x))\n}\n# Create and register a parallel cluster\ncl &lt;- makeCluster(detectCores()-1)\nregisterDoParallel(cl)\n\n# Run the loop 100 times in parallel, row-binding the results\nresults &lt;- foreach(i = 1:100, .combine = rbind) %dopar% {\n mv(i)\n}\n\n# Stop the cluster\nstopCluster(cl)\n\n# Display the results\nprint(results)\n\n                mean   variance\nresult.1   1.1288992 0.73035518\nresult.2   0.7950107 0.21141747\nresult.3   0.3583200 0.06563397\nresult.4   0.8106077 0.78682642\nresult.5   1.5510018 3.64689240\nresult.6   1.4773638 1.56826896\nresult.7   0.4197574 0.13742353\nresult.8   1.1423358 2.53882291\nresult.9   0.4153431 0.01160518\nresult.10  0.2755864 0.11912366\nresult.11  1.2601540 1.07318467\nresult.12  1.7475335 2.92147586\nresult.13  1.3302222 3.87939260\nresult.14  0.6447782 0.34432987\nresult.15  1.0684831 1.32564220\nresult.16  1.7598558 0.93240282\nresult.17  0.9087562 1.09592852\nresult.18  1.5613996 2.26774037\nresult.19  0.7621280 0.35850302\nresult.20  0.7591938 0.85965785\nresult.21  1.5856916 0.51469177\nresult.22  1.0630074 2.07856419\nresult.23  1.2412400 1.18889830\nresult.24  0.6320390 0.20168502\nresult.25  0.4186786 0.04573243\nresult.26  1.2200079 1.55888103\nresult.27  0.8936621 0.63438404\nresult.28  0.7822015 0.66555297\nresult.29  0.4296315 0.09811357\nresult.30  1.5339749 2.93832528\nresult.31  1.3359452 0.77659875\nresult.32  1.2243813 0.25632603\nresult.33  1.3048900 1.84245975\nresult.34  0.8163190 0.16284323\nresult.35  1.4042810 0.50133200\nresult.36  0.7544900 0.67435215\nresult.37  0.9553073 0.22037393\nresult.38  0.9734162 0.34116689\nresult.39  1.0024035 1.30177623\nresult.40  1.1883327 1.76926033\nresult.41  0.3378147 0.19666427\nresult.42  1.1764654 3.37297975\nresult.43  1.1048075 0.94397295\nresult.44  1.3092370 0.59307765\nresult.45  1.0635728 0.96833769\nresult.46  1.8146406 1.00234279\nresult.47  1.3141530 0.72582506\nresult.48  2.0089726 5.40000362\nresult.49  0.9712787 1.06853051\nresult.50  2.0516110 2.42725116\nresult.51  1.1371917 0.87397629\nresult.52  0.3539980 0.15217264\nresult.53  2.1923255 3.28910959\nresult.54  1.1433682 0.61960775\nresult.55  0.6413180 0.23746845\nresult.56  0.9745443 0.31693026\nresult.57  1.2596828 0.46997846\nresult.58  0.6733489 0.17728644\nresult.59  0.6558711 0.11192639\nresult.60  0.2869652 0.05203253\nresult.61  0.7912332 0.88691298\nresult.62  1.0032570 0.85523386\nresult.63  0.9848363 0.94665859\nresult.64  0.4565007 0.13055929\nresult.65  0.8776881 1.03896356\nresult.66  0.8329913 2.14057435\nresult.67  1.7084647 2.30072970\nresult.68  1.7559917 1.49152952\nresult.69  0.9423884 1.16791953\nresult.70  1.0121772 1.47473197\nresult.71  0.7984874 0.23523992\nresult.72  1.0125662 1.48196792\nresult.73  0.6378034 0.20705218\nresult.74  0.8283713 1.01516138\nresult.75  0.3757705 0.07238936\nresult.76  1.2645921 1.99987744\nresult.77  0.7874910 0.23039238\nresult.78  0.3777147 0.11149824\nresult.79  1.1175695 1.61746429\nresult.80  1.7247620 2.84546887\nresult.81  1.0671121 1.02452935\nresult.82  1.7984154 2.21659650\nresult.83  0.6359398 0.17242037\nresult.84  0.9046533 0.42237020\nresult.85  1.4731696 2.83351935\nresult.86  1.2016286 2.43604612\nresult.87  0.4626624 0.08911491\nresult.88  1.0546414 1.48970702\nresult.89  0.5144586 0.14163034\nresult.90  1.8080100 6.41394861\nresult.91  1.8079900 0.56166578\nresult.92  1.2877671 0.61062531\nresult.93  0.9869252 2.10192679\nresult.94  1.3554280 0.59870810\nresult.95  1.7970576 2.45921712\nresult.96  1.4589206 0.50374303\nresult.97  0.5805582 0.21950760\nresult.98  0.7262184 0.51128350\nresult.99  1.3386200 4.30815936\nresult.100 0.8891374 0.67267828"
  },
  {
    "objectID": "Practical2.html#question-2",
    "href": "Practical2.html#question-2",
    "title": "Practical 2",
    "section": "Question 2",
    "text": "Question 2\n\n# Load necessary libraries\nlibrary(MASS)         # For galaxies data\nlibrary(doParallel)   # For parallel backend\nlibrary(foreach)      # For the foreach loop\n\n# Load the galaxies data\ndata(galaxies)\n\n# Set the number of bootstrap samples\nn_boot &lt;- 10000\n\n# Serial Bootstrapping\nset.seed(123)\nserial_time &lt;- system.time({\n  boot_medians_ser &lt;- foreach(i = 1:n_boot, .combine = c, .packages = \"MASS\") %do% {\n    median(sample(galaxies, size=length(galaxies), replace = TRUE))\n  }\n})\n\ncat(\"Serial processing time:\\n\")\n\nSerial processing time:\n\nprint(serial_time)\n\n   user  system elapsed \n  2.124   0.011   2.136 \n\n# Parallel Bootstrapping: One Bootstrap per Iteration\n# Set up parallel backend\nncores &lt;- parallel::detectCores() - 1\ncl &lt;- makeCluster(ncores)\nregisterDoParallel(cl)\n\nset.seed(123)\nparallel_time &lt;- system.time({\n  boot_medians_parallel &lt;- foreach(i = 1:n_boot, .packages = 'MASS') %dopar% {\n    sample_data &lt;- sample(galaxies, size= length(galaxies), replace = TRUE)\n    median(sample_data)\n  }\n})\ncat(\"Parallel processing time (one bootstrap per iteration):\\n\")\n\nParallel processing time (one bootstrap per iteration):\n\nprint(parallel_time)\n\n   user  system elapsed \n  2.738   0.273   3.256 \n\n# Parallel Bootstrapping: 1000 Bootstraps per Iteration (Chunking)\n# Determine number of chunks\nchunk_size &lt;- 1000\nn_chunks &lt;- n_boot / chunk_size  # here, 10 chunks if n_boot = 10000\n\nset.seed(123)\nchunk_parallel_time &lt;- system.time({\n  boot_medians_chunk &lt;- foreach(i = 1:n_chunks, .packages = 'MASS', .combine = c) %dopar% {\n    # For each chunk, perform 1000 bootstrap samples\n    sapply(1:chunk_size, function(j) {\n      sample_data &lt;-sample(galaxies,size=length(galaxies),       replace = TRUE)\n      median(sample_data)\n    })\n  }\n})\ncat(\"Parallel processing time (1000 bootstraps per iteration):\\n\")\n\nParallel processing time (1000 bootstraps per iteration):\n\nprint(chunk_parallel_time)\n\n   user  system elapsed \n  0.012   0.002   0.205 \n\n# Shut down the cluster\nstopCluster(cl)\n\nWhen each iteration is very quick (like a single bootstrap), parallel processing can add significant overhead and actually slow down the computation. However, when you increase the work per iteration (e.g., 1000 bootstraps per iteration), the computational load becomes large enough relative to the overhead that parallel processing offers a substantial speedup over serial processing."
  },
  {
    "objectID": "Practical2.html#question-3",
    "href": "Practical2.html#question-3",
    "title": "Practical 2",
    "section": "Question 3",
    "text": "Question 3\n\n## Parallel Processing Code\nlibrary(doParallel)\nlibrary(foreach)\n# Set a seed for reproducibility\nset.seed(123)\n\n# Parameters\nn &lt;- 50       # Sample size for each simulation\nB &lt;- 1000     # Number of bootstrap replications per simulation\nnsim &lt;- 1000  # Number of simulation iterations for coverage estimation\n\n# Create and register a cluster (using 3 cores in this example)\ncl &lt;- makeCluster(detectCores()-1)\nregisterDoParallel(cl)\n\nparallel_time &lt;- system.time({\n  # Use foreach in parallel to simulate nsim times\n  coverage_parallel &lt;- foreach(sim = 1:nsim, .combine = c) %dopar% {\n    # Draw a sample of size n from Exp(1)\n    sample_data &lt;- rexp(n, rate = 1)\n    \n    # Bootstrap the sample mean B times\n    boot_means &lt;- replicate(B, mean(sample(sample_data, size = n, replace = TRUE)))\n    \n    # Calculate the 95% percentile bootstrap CI\n    ci &lt;- quantile(boot_means, probs = c(0.025, 0.975))\n    \n    # Return 1 if the true mean (1) is within the CI, else 0\n    as.numeric(1 &gt;= ci[1] & 1 &lt;= ci[2])\n  }\n})\n# Estimate the coverage probability\ncoverage_prob_parallel &lt;- mean(coverage_parallel)\n\n# Stop the cluster after parallel processing is complete\nstopCluster(cl)\n\n\n## Results\ncat(\"Parallel processing time:\\n\")\n\nParallel processing time:\n\nprint(parallel_time)\n\n   user  system elapsed \n  0.570   0.238   9.512 \n\ncat(\"Estimated coverage (parallel):\", coverage_prob_parallel, \"\\n\\n\")\n\nEstimated coverage (parallel): 0.925"
  },
  {
    "objectID": "Practical2.html#question-4",
    "href": "Practical2.html#question-4",
    "title": "Practical 2",
    "section": "Question 4",
    "text": "Question 4\n\nlibrary(doParallel)\nlibrary(foreach)\nlibrary(iterators)\n\nset.seed(1234)\n\n# Set up a parallel backend using available cores\ncl &lt;- makeCluster(detectCores() - 1)\nregisterDoParallel(cl)\n\n# Use foreach: for each iteration (1:3), create an iterator for one vector of 5 normals,\n# extract the vector, and compute its maximum.\nresults &lt;- foreach(i = 1:3, .combine = c, .packages = \"iterators\") %dopar% {\n  vec_iter &lt;- irnorm(1, n = 5)  \n  vec &lt;- nextElem(vec_iter)     \n  max(vec)                     \n}\n\n# Stop the cluster\nstopCluster(cl)\n\n# Print the results\nprint(results)\n\n[1] 3.238682 1.853422 1.303401\n\n\n##Question 5\n\n# Setup\nlibrary(iterators)\nlibrary(foreach)\nlibrary(doParallel)\nlibrary(parallel)\n\n# Define parameters\nnum_iter &lt;- 3  # Number of vectors to generate\nn &lt;- 5         # Number of random normals per vector\n\n# Set the seed for reproducibility\nset.seed(1234)\n\n# -----------------------\n# Method 1: Using parLapply (Parallel)\n# -----------------------\n# Create a parallel cluster\ncl1 &lt;- makeCluster(detectCores() - 1)\nregisterDoParallel(cl1)\n# Export the variable 'n' to the cluster and load 'iterators' on each worker\nclusterExport(cl1, varlist = \"n\")\nc &lt;- clusterEvalQ(cl1, library(iterators))\n\n# Measure time for parLapply\nparLapply_time &lt;- system.time({\n  parLapply_results &lt;- parLapply(cl1, 1:num_iter, function(i) {\n    vec_iter &lt;- irnorm(1, n = n)\n    vec &lt;- nextElem(vec_iter)\n    max(vec)\n  })\n  parLapply_results &lt;- unlist(parLapply_results)\n})\nstopCluster(cl1)  # Shut down the cluster\n\n\n# Using foreach \nforeach_time &lt;- system.time({\n  foreach_results &lt;- foreach(i = 1:num_iter, .combine = c,\n                             .packages = \"iterators\",\n                             .export = \"n\") %do% {\n    vec_iter &lt;- irnorm(1, n = n)\n    vec &lt;- nextElem(vec_iter)\n    max(vec)\n  }\n})\n\n#Using replicate (Sequential)\nreplicate_time &lt;- system.time({\n  replicate_results &lt;- replicate(num_iter, {\n    vec_iter &lt;- irnorm(1, n = n)\n    vec &lt;- nextElem(vec_iter)\n    max(vec)\n  })\n})\n\n# Print the results and timing comparisons\n\ncat(\"parLapply results:\\n\")\n\nparLapply results:\n\nprint(parLapply_time)\n\n   user  system elapsed \n  0.004   0.001   0.006 \n\ncat(\"\\nforeach results:\\n\")\n\n\nforeach results:\n\nprint(foreach_time)\n\n   user  system elapsed \n  0.008   0.002   0.012 \n\ncat(\"\\nreplicate results:\\n\")\n\n\nreplicate results:\n\nprint(replicate_time)\n\n   user  system elapsed \n  0.002   0.000   0.002"
  }
]