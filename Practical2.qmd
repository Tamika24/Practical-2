---
title: "Practical 2"
format: html
---

## Question 1

```{r}
#| echo: true
# Load necessary libraries
library(foreach)
library(doParallel)
library(knitr)

# Set up a parallel backend with one fewer than available cores
ncores <- parallel::detectCores() - 1
cl <- makeCluster(ncores)
registerDoParallel(cl)

# Number of simulations and sample size for each simulation
num_simulations <- 100
sample_size <- 100  # you can change this if needed

# Use a foreach loop to run the simulation 100 times
results <- foreach(i = 1:num_simulations, .combine = rbind) %dopar% {
  # Generate a random sample from an exponential distribution with mean = 1
  sample_data <- rexp(sample_size, rate = 1)
  
  # Calculate the mean and variance of the sample
  sample_mean <- mean(sample_data)
  sample_variance <- var(sample_data)
  
  # Return a vector with the mean and variance
  c(mean = sample_mean, variance = sample_variance)
}

# Stop the parallel cluster
stopCluster(cl)

# Display the first few rows of the results
cat("The results are :")
results
```

## Question 2

```{r}
#| echo: true
# Load necessary libraries
library(MASS)         # For galaxies data
library(doParallel)   # For parallel backend
library(foreach)      # For the foreach loop

# Load the galaxies data
data(galaxies)

# Set the number of bootstrap samples
n_boot <- 10000

# Serial Bootstrapping
set.seed(123)
serial_time <- system.time({
  boot_medians_serial <- replicate(n_boot, {
    sample_data <- sample(galaxies, replace = TRUE)
    median(sample_data)
  })
})
cat("Serial processing time:\n")
print(serial_time)

# Parallel Bootstrapping: One Bootstrap per Iteration
# Set up parallel backend
ncores <- parallel::detectCores() - 1
cl <- makeCluster(ncores)
registerDoParallel(cl)

set.seed(123)
parallel_time <- system.time({
  boot_medians_parallel <- foreach(i = 1:n_boot, .packages = 'MASS') %dopar% {
    sample_data <- sample(galaxies, replace = TRUE)
    median(sample_data)
  }
})
cat("Parallel processing time (one bootstrap per iteration):\n")
print(parallel_time)

# Parallel Bootstrapping: 1000 Bootstraps per Iteration (Chunking)
# Determine number of chunks
chunk_size <- 1000
n_chunks <- n_boot / chunk_size  # here, 10 chunks if n_boot = 10000

set.seed(123)
chunk_parallel_time <- system.time({
  boot_medians_chunk <- foreach(i = 1:n_chunks, .packages = 'MASS', .combine = c) %dopar% {
    # For each chunk, perform 1000 bootstrap samples
    sapply(1:chunk_size, function(j) {
      sample_data <- sample(galaxies, replace = TRUE)
      median(sample_data)
    })
  }
})
cat("Parallel processing time (1000 bootstraps per iteration):\n")
print(chunk_parallel_time)

# Shut down the cluster
stopCluster(cl)
```

When each iteration is very quick (like a single bootstrap), parallel processing can add significant overhead and actually slow down the computation. However, when you increase the work per iteration (e.g., 1000 bootstraps per iteration), the computational load becomes large enough relative to the overhead that parallel processing offers a substantial speedup over serial processing.

## Question 3

```{r}
#| echo: true
# Set simulation parameters
set.seed(123)        # For reproducibility
n <- 50              # Sample size
M <- 1000            # Number of simulation iterations
B <- 1000            # Number of bootstrap replicates per iteration

# Vector to record if the CI covers the true mean (1) for each simulation
coverage <- numeric(M)

for(i in 1:M) {
  # Draw a sample of size 50 from an exponential distribution (mean = 1)
  sample_data <- rexp(n, rate = 1)
  
  # Bootstrap: compute the mean for B bootstrap samples
  boot_means <- replicate(B, mean(sample(sample_data, size = n, replace = TRUE)))
  
  # Compute the 95% percentile bootstrap confidence interval
  ci <- quantile(boot_means, probs = c(0.025, 0.975))
  
  # Check if the true mean (1) falls within the CI
  coverage[i] <- as.numeric( (1 >= ci[1]) & (1 <= ci[2]) )
}

# Calculate the coverage probability
coverage_probability <- mean(coverage)
cat("Estimated coverage probability:", coverage_probability, "\n")


```

## Question 4

```{r}
#| echo: true
library(doParallel)
library(foreach)
library(iterators)

set.seed(1234)

# Set up a parallel backend using available cores
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

# Use foreach: for each iteration (1:3), create an iterator for one vector of 5 normals,
# extract the vector, and compute its maximum.
results <- foreach(i = 1:3, .combine = c, .packages = "iterators") %dopar% {
  vec_iter <- irnorm(1, n = 5)  # returns an iterator for 1 vector
  vec <- nextElem(vec_iter)     # extract the numeric vector from the iterator
  max(vec)                     # compute the maximum value
}

# Stop the cluster
stopCluster(cl)

# Print the results
print(results)

```

##Question 5

```{r}
#| echo: true
# -----------------------
# Setup
# -----------------------
library(iterators)
library(foreach)
library(doParallel)
library(parallel)

# Define parameters
num_iter <- 3  # Number of vectors to generate
n <- 5         # Number of random normals per vector

# Set the seed for reproducibility
set.seed(1234)

# -----------------------
# Method 1: Using parLapply (Parallel)
# -----------------------
# Create a parallel cluster
cl1 <- makeCluster(detectCores() - 1)

# Export the variable 'n' to the cluster and load 'iterators' on each worker
clusterExport(cl1, varlist = "n")
c <- clusterEvalQ(cl1, library(iterators))

# Measure time for parLapply
parLapply_time <- system.time({
  parLapply_results <- parLapply(cl1, 1:num_iter, function(i) {
    # Create an iterator for one vector of n random normals
    vec_iter <- irnorm(1, n = n)
    # Extract the numeric vector from the iterator
    vec <- nextElem(vec_iter)
    # Return the maximum value from the vector
    max(vec)
  })
  parLapply_results <- unlist(parLapply_results)
})
stopCluster(cl1)  # Shut down the cluster

# -----------------------
# Method 2: Using foreach with %dopar% (Parallel)
# -----------------------
cl2 <- makeCluster(detectCores() - 1)
registerDoParallel(cl2)

# Measure time for foreach; export 'n' and load the 'iterators' package on each worker.
foreach_time <- system.time({
  foreach_results <- foreach(i = 1:num_iter, .combine = c,
                             .packages = "iterators",
                             .export = "n") %dopar% {
    vec_iter <- irnorm(1, n = n)
    vec <- nextElem(vec_iter)
    max(vec)
  }
})
stopCluster(cl2)

# -----------------------
# Method 3: Using replicate (Sequential)
# -----------------------
replicate_time <- system.time({
  replicate_results <- replicate(num_iter, {
    vec_iter <- irnorm(1, n = n)
    vec <- nextElem(vec_iter)
    max(vec)
  })
})

# -----------------------
# Print the results and timing comparisons
# -----------------------
cat("Results and timings:\n\n")

cat("parLapply results:\n")
print(parLapply_results)
print(parLapply_time)

cat("\nforeach (%dopar%) results:\n")
print(foreach_results)
print(foreach_time)

cat("\nreplicate results:\n")
print(replicate_results)
print(replicate_time)

```