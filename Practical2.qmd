---
title: "Practical 2"
format: html
---

## Question 1

```{r}
#| echo: true
# Load required packages
library(doParallel)
library(foreach)

mv <- function(i){
  x <- rexp(100, rate = 1)
  c(mean = mean(x), variance = var(x))
}
# Create and register a parallel cluster
cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)

# Run the loop 100 times in parallel, row-binding the results
results <- foreach(i = 1:100, .combine = rbind) %dopar% {
 mv(i)
}

# Stop the cluster
stopCluster(cl)

# Display the results
print(results)
```

## Question 2

```{r}
#| echo: true
# Load necessary libraries
library(MASS)         # For galaxies data
library(doParallel)   # For parallel backend
library(foreach)      # For the foreach loop

# Load the galaxies data
data(galaxies)

# Set the number of bootstrap samples
n_boot <- 10000

# Serial Bootstrapping
set.seed(123)
serial_time <- system.time({
  boot_medians_ser <- foreach(i = 1:nboot, .combine = c, .packages = "MASS") %do% {
    median(sample(galaxies, replace = TRUE))
  }
})

cat("Serial processing time:\n")
print(serial_time)

# Parallel Bootstrapping: One Bootstrap per Iteration
# Set up parallel backend
ncores <- parallel::detectCores() - 1
cl <- makeCluster(ncores)
registerDoParallel(cl)

set.seed(123)
parallel_time <- system.time({
  boot_medians_parallel <- foreach(i = 1:n_boot, .packages = 'MASS') %dopar% {
    sample_data <- sample(galaxies, replace = TRUE)
    median(sample_data)
  }
})
cat("Parallel processing time (one bootstrap per iteration):\n")
print(parallel_time)

# Parallel Bootstrapping: 1000 Bootstraps per Iteration (Chunking)
# Determine number of chunks
chunk_size <- 1000
n_chunks <- n_boot / chunk_size  # here, 10 chunks if n_boot = 10000

set.seed(123)
chunk_parallel_time <- system.time({
  boot_medians_chunk <- foreach(i = 1:n_chunks, .packages = 'MASS', .combine = c) %dopar% {
    # For each chunk, perform 1000 bootstrap samples
    sapply(1:chunk_size, function(j) {
      sample_data <- sample(galaxies, replace = TRUE)
      median(sample_data)
    })
  }
})
cat("Parallel processing time (1000 bootstraps per iteration):\n")
print(chunk_parallel_time)

# Shut down the cluster
stopCluster(cl)
```

When each iteration is very quick (like a single bootstrap), parallel processing can add significant overhead and actually slow down the computation. However, when you increase the work per iteration (e.g., 1000 bootstraps per iteration), the computational load becomes large enough relative to the overhead that parallel processing offers a substantial speedup over serial processing.

## Question 3

```{r}
#| echo: true
## Parallel Processing Code
library(doParallel)
library(foreach)
# Set a seed for reproducibility
set.seed(123)

# Parameters
n <- 50       # Sample size for each simulation
B <- 1000     # Number of bootstrap replications per simulation
nsim <- 1000  # Number of simulation iterations for coverage estimation

# Create and register a cluster (using 3 cores in this example)
cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)

parallel_time <- system.time({
  # Use foreach in parallel to simulate nsim times
  coverage_parallel <- foreach(sim = 1:nsim, .combine = c) %dopar% {
    # Draw a sample of size n from Exp(1)
    sample_data <- rexp(n, rate = 1)
    
    # Bootstrap the sample mean B times
    boot_means <- replicate(B, mean(sample(sample_data, size = n, replace = TRUE)))
    
    # Calculate the 95% percentile bootstrap CI
    ci <- quantile(boot_means, probs = c(0.025, 0.975))
    
    # Return 1 if the true mean (1) is within the CI, else 0
    as.numeric(1 >= ci[1] & 1 <= ci[2])
  }
})
# Estimate the coverage probability
coverage_prob_parallel <- mean(coverage_parallel)

# Stop the cluster after parallel processing is complete
stopCluster(cl)

## Sequential Processing Code
serial_time <- system.time({
  coverage_serial <- numeric(nsim)
  
  for (sim in 1:nsim) {
    sample_data <- rexp(n, rate = 1)
    boot_means <- replicate(B, mean(sample(sample_data, size = n, replace = TRUE)))
    ci <- quantile(boot_means, probs = c(0.025, 0.975))
    coverage_serial[sim] <- as.numeric(1 >= ci[1] & 1 <= ci[2])
  }
})
coverage_prob_serial <- mean(coverage_serial)

## Results
cat("Parallel processing time:\n")
print(parallel_time)
cat("Estimated coverage (parallel):", coverage_prob_parallel, "\n\n")

cat("Sequential processing time:\n")
print(serial_time)
cat("Estimated coverage (sequential):", coverage_prob_serial, "\n")

```

## Question 4

```{r}
#| echo: true
library(doParallel)
library(foreach)
library(iterators)

set.seed(1234)

# Set up a parallel backend using available cores
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

# Use foreach: for each iteration (1:3), create an iterator for one vector of 5 normals,
# extract the vector, and compute its maximum.
results <- foreach(i = 1:3, .combine = c, .packages = "iterators") %dopar% {
  vec_iter <- irnorm(1, n = 5)  
  vec <- nextElem(vec_iter)     
  max(vec)                     
}

# Stop the cluster
stopCluster(cl)

# Print the results
print(results)

```

##Question 5

```{r}
#| echo: true
# -----------------------
# Setup
# -----------------------
library(iterators)
library(foreach)
library(doParallel)
library(parallel)

# Define parameters
num_iter <- 3  # Number of vectors to generate
n <- 5         # Number of random normals per vector

# Set the seed for reproducibility
set.seed(1234)

# -----------------------
# Method 1: Using parLapply (Parallel)
# -----------------------
# Create a parallel cluster
cl1 <- makeCluster(detectCores() - 1)
registerDoParallel(cl1)
# Export the variable 'n' to the cluster and load 'iterators' on each worker
clusterExport(cl1, varlist = "n")
c <- clusterEvalQ(cl1, library(iterators))

# Measure time for parLapply
parLapply_time <- system.time({
  parLapply_results <- parLapply(cl1, 1:num_iter, function(i) {
    vec_iter <- irnorm(1, n = n)
    vec <- nextElem(vec_iter)
    max(vec)
  })
  parLapply_results <- unlist(parLapply_results)
})
stopCluster(cl1)  # Shut down the cluster


# Using foreach 
foreach_time <- system.time({
  foreach_results <- foreach(i = 1:num_iter, .combine = c,
                             .packages = "iterators",
                             .export = "n") %do% {
    vec_iter <- irnorm(1, n = n)
    vec <- nextElem(vec_iter)
    max(vec)
  }
})

#Using replicate (Sequential)
replicate_time <- system.time({
  replicate_results <- replicate(num_iter, {
    vec_iter <- irnorm(1, n = n)
    vec <- nextElem(vec_iter)
    max(vec)
  })
})

# Print the results and timing comparisons
cat("Results and timings:\n\n")

cat("parLapply results:\n")
print(parLapply_results)
print(parLapply_time)

cat("\nforeach (%dopar%) results:\n")
print(foreach_results)
print(foreach_time)

cat("\nreplicate results:\n")
print(replicate_results)
print(replicate_time)

```